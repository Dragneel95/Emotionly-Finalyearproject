{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Emotion Detection - Lexicon Based approach\n",
    "'''\n",
    "from __future__ import division\n",
    "import nltk \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "from nltk.classify.naivebayes import NaiveBayesClassifier\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.corpus import wordnet as wn\n",
    "import urllib\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n36 - Class Label\\n40 - Sentence\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Reading the Dataset (ISEAR Dataset)\n",
    "'''\n",
    "Data = pd.read_csv('ISEAR.csv',header=None)\n",
    "'''\n",
    "36 - Class Label\n",
    "40 - Sentence\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Emotion Labels\n",
    "'''\n",
    "emotion_labels = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a list of all corresponding class labels\n",
    "'''\n",
    "def class_labels(emotions):\n",
    "    labels = []\n",
    "    labelset = []\n",
    "    exclude = []\n",
    "    for i in range(len(emotions)):\n",
    "#         labels.append(e)\n",
    "#         labelset.append([e])\n",
    "        if emotions[i] not in ['shame','guilt']:\n",
    "            labels.append(e)\n",
    "            labelset.append([e])\n",
    "        else:\n",
    "            exclude.append(i)\n",
    "    return labels, labelset, exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Removes unnecessary characters from sentences\n",
    "'''\n",
    "def removal(sentences):\n",
    "    sentence_list = []\n",
    "    count = 0\n",
    "#     for sen in sentences:\n",
    "#         count += 1\n",
    "#         print count\n",
    "#         print sen\n",
    "#         print type(sen)\n",
    "    s = nltk.word_tokenize(sentences)\n",
    "    characters = [\"รก\", \"\\xc3\", \"\\xa1\", \"\\n\", \",\", \".\", \"[\", \"]\", \"\"]\n",
    "    l = []\n",
    "    for t in s:\n",
    "        if t not in characters:\n",
    "            l.append(t)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "POS-TAGGER, returns NAVA words\n",
    "'''\n",
    "def pos_tag(sentences):\n",
    "    tags = [] #have the pos tag included\n",
    "    nava_sen = []\n",
    "    pt = nltk.pos_tag(sentences)\n",
    "#     for s in sentences:\n",
    "#     s_token = nltk.word_tokenize(sentences)\n",
    "#     pt = nltk.pos_tag(s_token)\n",
    "    nava = []\n",
    "    nava_words = []\n",
    "    for t in pt:\n",
    "        if t[1].startswith('NN') or t[1].startswith('JJ') or t[1].startswith('VB') or t[1].startswith('RB'):\n",
    "            nava.append(t)\n",
    "            nava_words.append(t[0])\n",
    "    return nava, nava_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Performs stemming\n",
    "'''\n",
    "def stemming(sentences):\n",
    "    sentence_list = []\n",
    "    sen_string = []\n",
    "    sen_token = []\n",
    "    stemmer = PorterStemmer()\n",
    "    i = 0\n",
    "#     for sen in sentences:\n",
    "#         print i,\n",
    "    i += 1\n",
    "    st = \"\"\n",
    "    for word in sentences:\n",
    "        word_l = word.lower()\n",
    "        if len(word_l) >= 3:\n",
    "            st += stemmer.stem(word_l) + \" \"\n",
    "    sen_string.append(st)\n",
    "    w_set = nltk.word_tokenize(st)\n",
    "    sen_token.append(w_set)\n",
    "    w_text = nltk.Text(w_set)\n",
    "    sentence_list.append(w_text)\n",
    "    return w_text, st, w_set\n",
    "#     return sentence_list, sen_string, sen_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write to file\n",
    "'''\n",
    "def write_to_file(filename, text):\n",
    "    o = open(filename,'w')\n",
    "    o.write(str(text))\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating the dataframe\n",
    "'''\n",
    "def create_frame(Data):\n",
    "    labels = []\n",
    "    sen = []\n",
    "    sen_s = []\n",
    "    sen_t = []\n",
    "    labelset = []\n",
    "    for i in range(len(Data)):\n",
    "        if i >= 0:\n",
    "            emotion = Data[0][i]\n",
    "            sit = Data[1][i]\n",
    "            labels.append(emotion)\n",
    "            labelset.append([emotion])\n",
    "            sent = removal(sit)\n",
    "            nava, sent_pt = pos_tag(sent)\n",
    "            sentences, sen_string, sen_token = stemming(sent_pt)\n",
    "            sen.append(sentences)\n",
    "            sen_s.append(sen_string)\n",
    "            sen_t.append(sen_token)\n",
    "    frame = pd.DataFrame({0 : labels,\n",
    "                          1 : sen,\n",
    "                          2 : sen_s,\n",
    "                          3 : sen_t,\n",
    "                          4 : labelset})\n",
    "    return frame, sen_t, labels, sen_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c, st, labels, senten = create_frame(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reads the emotion representative words file\n",
    "'''\n",
    "def readfile(filename):\n",
    "    f = open(filename,'r')\n",
    "    representative_words = []\n",
    "    for line in f.readlines():\n",
    "        characters = [\"\\n\", \" \", \"\\r\", \"\\t\"]\n",
    "        new = ''.join([i for i in line if not [e for e in characters if e in i]])\n",
    "        representative_words.append(new)\n",
    "    return representative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Makes a list of all words semantically related to an emotion and Stemming\n",
    "'''\n",
    "def affect_wordlist(words):\n",
    "    affect_words = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for w in words:\n",
    "        w_l = w.lower()\n",
    "        word_stem = stemmer.stem(w_l)\n",
    "        if word_stem not in affect_words:\n",
    "            affect_words.append(word_stem)\n",
    "    return affect_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating an emotion wordnet\n",
    "'''\n",
    "def emotion_word_set(emotions):\n",
    "    word_set = {}\n",
    "    for e in emotions:\n",
    "        representative_words = readfile(e)\n",
    "        wordlist = affect_wordlist(representative_words)\n",
    "        word_set[e] = wordlist\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Lexicon based approach - Check for lexicons\n",
    "The function checks if the input sentence contains any lexicons. If it does, it stores them as shown in the example.\n",
    "eg: {u'love': ['joy']}, {u'death': ['fear']}\n",
    "The sentence contains two words, 'love' (which indicates joy) and 'death' (which indicates fear).\n",
    "'''\n",
    "def lexicon_based(sentences, word_set):\n",
    "    text_vector = []\n",
    "    for sen in sentences:\n",
    "        s_vector = []\n",
    "        for word in sen:\n",
    "            w_vector = {}\n",
    "            for emo in word_set:\n",
    "                if word in word_set[emo]:\n",
    "                    try:\n",
    "                        if emo not in w_vector[word]:\n",
    "                            w_vector[word].append(emo)\n",
    "                    except KeyError:\n",
    "                        w_vector[word] = [emo]\n",
    "            if w_vector:\n",
    "                s_vector.append(w_vector)\n",
    "        if not s_vector:\n",
    "            text_vector.append(s_vector)\n",
    "        else:\n",
    "            text_vector.append(s_vector)\n",
    "    return text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Lexicon based approach - Classify based on lexicons\n",
    "This function tries to detect the emotion in the sentence based on the lexicons extracted by the function named 'lexicon_based'\n",
    "'''\n",
    "def classify_lexicon(text_vector, labels, emotion_labels):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for j in range(len(text_vector)):\n",
    "        sen = text_vector[j]\n",
    "        sen_emo = np.empty(len(emotion_labels))\n",
    "        sen_emo.fill(0)\n",
    "        if sen:\n",
    "            total += 1\n",
    "            w_emo = []\n",
    "            for word in sen:\n",
    "                emotions =  word.values()[0][0]\n",
    "                w_emo.append(emotions)\n",
    "                i = emotion_labels.index(emotions)\n",
    "                sen_emo[i] += 1\n",
    "            winner = np.argwhere(sen_emo == np.amax(sen_emo))\n",
    "            indices = winner.flatten().tolist()\n",
    "            for i in indices:\n",
    "                if emotion_labels[i] == labels[j]:\n",
    "                    count += 1\n",
    "                    break\n",
    "    accuracy = count/len(text_vector)\n",
    "    tot_accuracy = count/total\n",
    "    return accuracy, tot_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total accuracy of the lexicon based approach =  22.7514635444 %\n",
      "The accuracy when only those sentences that contain the lexicon are considered for evaluation =  54.0113708149 %\n"
     ]
    }
   ],
   "source": [
    "e = emotion_word_set(emotion_labels)\n",
    "l = lexicon_based(c[1],e) \n",
    "a, b = classify_lexicon(l, c[0], emotion_labels)\n",
    "print \"The total accuracy of the lexicon based approach = \", a*100 , \"%\"\n",
    "print \"The accuracy when only those sentences that contain the lexicon are considered for evaluation = \",b*100, \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
